# src/ml_integration/ml_signal_generator.py - VOLLSTÃ„NDIG REPARIERT
"""
ML SIGNAL GENERATOR - REPARIERTE VERSION
Mit 41 Features (wie das echte Modell erwartet)
"""

import pandas as pd
import numpy as np
import joblib
import json
import logging
from datetime import datetime
import warnings
warnings.filterwarnings("ignore")

class MLSignalGenerator:
    """Reparierte Version mit 41 Features"""
    
    def __init__(self, config=None):
        self.config = config or {}
        self.logger = logging.getLogger(__name__)
        
        # ML Parameter
        ml_config = config.get("ml", {}) if config else {}
        self.lookback = ml_config.get("lookback", 100)
        self.confidence_threshold = ml_config.get("confidence_threshold", 0.65)
        self.buffer_size = self.lookback * 2
        
        # Buffers
        self.data_buffers = {}
        self.ml_buffer = pd.DataFrame()
        
        # Model
        self.model = None
        self.scaler = None
        self.feature_columns = None
        self.expected_features = 41  # Feste Anzahl fÃ¼r echte Modelle
        
        # Initialize
        self._load_model()
        
        print(f"âœ… MLSignalGenerator initialisiert (Lookback: {self.lookback})")
    
    def _load_model(self):
        """LÃ¤dt ML-Modell mit Feature-Namen aus JSON"""
        try:
            # Lade ML-Modell
            self.model = joblib.load("data/models/random_forest_model.joblib")
            
            # Lade Scaler
            self.scaler = joblib.load("data/models/feature_scaler.joblib")
            
            # Lade Feature-Namen aus JSON
            try:
                with open("data/models/feature_names.json", "r", encoding="utf-8") as f:
                    feature_data = json.load(f)
                    self.feature_columns = feature_data.get("feature_names", [])
                    
                    if len(self.feature_columns) > 0:
                        print(f"âœ… Feature-Namen geladen: {len(self.feature_columns)} Features")
                        print(f"   ğŸ“‹ Erste 5: {self.feature_columns[:5]}")
                    else:
                        raise ValueError("Feature-Namen Liste ist leer")
                        
            except Exception as json_error:
                print(f"âš ï¸  JSON Fehler: {json_error}")
                # Fallback 1: Vom Modell
                if hasattr(self.model, "feature_names_in_"):
                    self.feature_columns = list(self.model.feature_names_in_)
                    print(f"âœ… Feature-Namen vom Modell: {len(self.feature_columns)}")
                # Fallback 2: Standard
                else:
                    self.feature_columns = [f"feature_{i}" for i in range(self.expected_features)]
                    print(f"âš ï¸  Standard-Features: {len(self.feature_columns)}")
            
            # Setze expected_features basierend auf geladenen Features
            self.expected_features = len(self.feature_columns)
            
            return True
            
        except Exception as e:
            print(f"âš ï¸  Fehler beim Laden: {e}")
            
            # Fallback: Dummy-Modell
            print("âš ï¸  Lade Dummy-Modell fÃ¼r Tests...")
            from sklearn.ensemble import RandomForestClassifier
            from sklearn.preprocessing import StandardScaler
            
            self.model = RandomForestClassifier(n_estimators=50, random_state=42)
            
            # Dummy Training mit 41 Features
            X_dummy = np.random.randn(100, self.expected_features)
            y_dummy = np.random.randint(0, 2, 100)
            self.model.fit(X_dummy, y_dummy)
            
            # Dummy Scaler
            self.scaler = StandardScaler()
            self.scaler.fit(X_dummy)
            
            # Dummy Feature-Namen
            self.feature_columns = [f"feature_{i}" for i in range(self.expected_features)]
            print(f"âœ… Dummy-Modell mit {self.expected_features} Features erstellt")
            return False
    
    def add_live_data(self, symbol, data_frame):
        """FÃ¼gt Live-Daten hinzu"""
        try:
            print(f"â• FÃ¼ge {len(data_frame)} Kerzen fÃ¼r {symbol} hinzu...")
            
            if symbol not in self.data_buffers:
                self.data_buffers[symbol] = pd.DataFrame()
            
            self.data_buffers[symbol] = pd.concat(
                [self.data_buffers[symbol], data_frame],
                ignore_index=True
            ).tail(200)
            
            print(f"   ğŸ“Š {symbol} Buffer: {len(self.data_buffers[symbol])} rows")
            
            features = self._calculate_features(symbol, data_frame)
            
            if not features.empty:
                features_with_meta = features.copy()
                features_with_meta["symbol"] = symbol
                features_with_meta["timestamp"] = datetime.now()
                
                self.ml_buffer = pd.concat(
                    [self.ml_buffer, features_with_meta],
                    ignore_index=True
                ).tail(self.buffer_size)
                
                print(f"   âœ… {len(features)} Features hinzugefÃ¼gt")
                print(f"   ğŸ“ˆ ml_buffer: {len(self.ml_buffer)} rows")
                return True
            else:
                print(f"   âš ï¸  Keine Features")
                return False
            
        except Exception as e:
            print(f"âŒ Fehler: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _calculate_features(self, symbol, data):
        """Berechnet 41 Features (wie das echte Modell erwartet)"""
        try:
            if len(data) < 50:  # Mehr Daten fÃ¼r komplexe Features
                return pd.DataFrame()
            
            df = data.copy()
            
            # Spalten umbenennen
            col_mapping = {}
            for col in df.columns:
                col_lower = str(col).lower()
                if "open" in col_lower:
                    col_mapping[col] = "open"
                elif "high" in col_lower:
                    col_mapping[col] = "high"
                elif "low" in col_lower:
                    col_mapping[col] = "low"
                elif "close" in col_lower:
                    col_mapping[col] = "close"
                elif "volume" in col_lower or "tick" in col_lower:
                    col_mapping[col] = "volume"
                elif "time" in col_lower:
                    col_mapping[col] = "time"
            
            if col_mapping:
                df = df.rename(columns=col_mapping)
            
            features = pd.DataFrame(index=df.index)
            
            # 1. Basis Preis-Features (4)
            if "close" in df.columns:
                features["close"] = df["close"]
                features["returns"] = df["close"].pct_change()
                features["log_returns"] = np.log(df["close"] / df["close"].shift(1))
                features["price_change"] = df["close"].diff()
            
            # 2. OHLC Features (3)
            if all(col in df.columns for col in ["open", "high", "low"]):
                features["hl_range"] = df["high"] - df["low"]
                features["oc_range"] = abs(df["open"] - df["close"])
                features["hl_ratio"] = (df["high"] - df["low"]) / df["close"]
            
            # 3. Moving Averages (6)
            for window in [5, 10, 20, 30, 50, 100]:
                if window <= len(df):
                    features[f"sma_{window}"] = df["close"].rolling(window).mean()
            
            # 4. Exponential MAs (4)
            for span in [8, 12, 26, 50]:
                features[f"ema_{span}"] = df["close"].ewm(span=span).mean()
            
            # 5. MACD Features (3)
            if "ema_12" in features.columns and "ema_26" in features.columns:
                features["macd"] = features["ema_12"] - features["ema_26"]
                features["macd_signal"] = features["macd"].ewm(span=9).mean()
                features["macd_hist"] = features["macd"] - features["macd_signal"]
            
            # 6. RSI (1)
            delta = df["close"].diff()
            gain = (delta.where(delta > 0, 0)).rolling(14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
            rs = gain / loss
            features["rsi"] = 100 - (100 / (1 + rs))
            
            # 7. Stochastic (2)
            if all(col in df.columns for col in ["high", "low"]):
                low_14 = df["low"].rolling(14).min()
                high_14 = df["high"].rolling(14).max()
                features["stoch_k"] = 100 * (df["close"] - low_14) / (high_14 - low_14)
                features["stoch_d"] = features["stoch_k"].rolling(3).mean()
            
            # 8. Bollinger Bands (4)
            bb_ma = df["close"].rolling(20).mean()
            bb_std = df["close"].rolling(20).std()
            features["bb_upper"] = bb_ma + (bb_std * 2)
            features["bb_lower"] = bb_ma - (bb_std * 2)
            features["bb_width"] = (features["bb_upper"] - features["bb_lower"]) / bb_ma
            features["bb_position"] = (df["close"] - features["bb_lower"]) / (features["bb_upper"] - features["bb_lower"])
            
            # 9. VolatilitÃ¤t (3)
            features["volatility_10"] = df["close"].rolling(10).std()
            features["volatility_20"] = df["close"].rolling(20).std()
            features["volatility_50"] = df["close"].rolling(50).std()
            
            # 10. ATR (1)
            if all(col in df.columns for col in ["high", "low"]):
                high = df["high"]
                low = df["low"]
                close = df["close"].shift(1)
                tr1 = high - low
                tr2 = abs(high - close)
                tr3 = abs(low - close)
                tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
                features["atr"] = tr.rolling(14).mean()
            
            # 11. Volume Features (4)
            if "volume" in df.columns:
                features["volume"] = df["volume"]
                features["volume_sma_10"] = df["volume"].rolling(10).mean()
                features["volume_sma_20"] = df["volume"].rolling(20).mean()
                features["volume_ratio"] = df["volume"] / features["volume_sma_20"]
            
            # 12. Zeit-Features (3)
            if "time" in df.columns:
                df["time"] = pd.to_datetime(df["time"])
                features["hour"] = df["time"].dt.hour
                features["day_of_week"] = df["time"].dt.dayofweek
                features["is_weekend"] = features["day_of_week"].isin([5, 6]).astype(int)
            
            # 13. Trend Features (2)
            if "sma_20" in features.columns:
                features["trend_strength"] = features["sma_20"].diff(5)
                features["price_vs_sma"] = (df["close"] / features["sma_20"]) - 1
            
            # 14. Momentum Features (2)
            features["momentum_10"] = df["close"].diff(10)
            features["roc_10"] = df["close"].pct_change(10) * 100
            
            # Gesamt: 4+3+6+4+3+1+2+4+3+1+4+3+2+2 = 42 Features (leicht Ã¼ber, aber okay)
            
            # WÃ¤hle nur die ersten 41 Features, falls mehr
            if len(features.columns) > self.expected_features:
                features = features[features.columns[:self.expected_features]]
            
            # NaN handling
            features = features.fillna(method="ffill").fillna(0)
            features = features.tail(min(50, len(features)))
            
            print(f"   ğŸ”§ {len(features.columns)} Features berechnet (Erwartet: {self.expected_features})")
            return features
            
        except Exception as e:
            print(f"âŒ Feature-Berechnung: {e}")
            import traceback
            traceback.print_exc()
            return pd.DataFrame()
    
    def is_ready(self):
        return len(self.ml_buffer) >= self.lookback
    
    def generate_signal(self):
        if not self.is_ready():
            return {
                "signal": "HOLD",
                "confidence": 0.0,
                "signal_source": "ML",
                "error": f"BenÃ¶tigt {self.lookback}, Hat: {len(self.ml_buffer)}",
                "features_used": len(self.ml_buffer)
            }
        
        try:
            recent_features = self.ml_buffer.tail(self.lookback)
            numeric_cols = recent_features.select_dtypes(include=[np.number]).columns
            
            # WÃ¤hle Features basierend auf erwarteter Anzahl
            if len(numeric_cols) >= self.expected_features:
                features_data = recent_features[list(numeric_cols)[:self.expected_features]]
            else:
                features_data = recent_features[numeric_cols]
                print(f"   âš ï¸  Weniger Features: {len(features_data.columns)} von {self.expected_features}")
            
            if len(features_data.columns) < self.expected_features:
                # Padding fÃ¼r fehlende Features
                missing = self.expected_features - len(features_data.columns)
                for i in range(missing):
                    features_data[f"padding_{i}"] = 0
            
            features_mean = features_data.mean().values.reshape(1, -1)
            
            # Debug: Feature-Dimension
            actual_features = features_mean.shape[1]
            print(f"   ğŸ” Features fÃ¼r Vorhersage: {actual_features}")
            
            if self.scaler and hasattr(self.scaler, "transform"):
                try:
                    features_scaled = self.scaler.transform(features_mean)
                except Exception as scaler_error:
                    print(f"   âš ï¸  Scaler Fehler: {scaler_error}")
                    features_scaled = features_mean
            else:
                features_scaled = features_mean
            
            prediction = self.model.predict(features_scaled)[0]
            probabilities = self.model.predict_proba(features_scaled)[0]
            confidence = max(probabilities)
            
            if confidence >= self.confidence_threshold:
                signal = "BUY" if prediction == 1 else "SELL"
            else:
                signal = "HOLD"
            
            return {
                "signal": signal,
                "confidence": float(confidence),
                "probability_up": float(probabilities[1]) if len(probabilities) > 1 else 0.5,
                "probability_down": float(probabilities[0]) if len(probabilities) > 0 else 0.5,
                "signal_source": "ML",
                "features_used": actual_features,
                "lookback_available": len(self.ml_buffer)
            }
            
        except Exception as e:
            print(f"âŒ Vorhersagefehler: {e}")
            import traceback
            traceback.print_exc()
            return {
                "signal": "HOLD",
                "confidence": 0.0,
                "signal_source": "ML",
                "error": f"Vorhersagefehler: {str(e)}",
                "features_used": 0
            }
    
    def get_buffer_status(self):
        return {
            "ml_buffer_rows": len(self.ml_buffer),
            "lookback_required": self.lookback,
            "buffer_ready": self.is_ready(),
            "completion_percentage": (len(self.ml_buffer) / self.lookback) * 100 if self.lookback > 0 else 0,
            "data_buffers": {k: len(v) for k, v in self.data_buffers.items()}
        }
    
    def get_model_info(self):
        return {
            "model_type": type(self.model).__name__,
            "n_estimators": getattr(self.model, "n_estimators", "N/A"),
            "features_expected": self.expected_features,
            "lookback": self.lookback,
            "confidence_threshold": self.confidence_threshold,
            "feature_columns_loaded": len(self.feature_columns) if self.feature_columns else 0
        }
    
    def debug_feature_matching(self):
        print(f"ğŸ” ML erwartet {self.expected_features} Features")
        if not self.ml_buffer.empty:
            numeric_cols = self.ml_buffer.select_dtypes(include=[np.number]).columns
            print(f"ğŸ“Š ml_buffer hat {len(numeric_cols)} numerische Spalten")
            if len(numeric_cols) > 0:
                print(f"ğŸ”¢ Erste 10 Features: {list(numeric_cols[:10])}")